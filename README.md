# Pseudo-code to C++ Code Generation with GPT-2

![Code Generation](https://img.shields.io/badge/Task-Code%20Generation-green)
![GPT-2](https://img.shields.io/badge/Model-GPT--2-purple)
![LoRA](https://img.shields.io/badge/Fine--tuning-LoRA-blue)

An advanced system for translating structured pseudo-code into executable C++ code using fine-tuned GPT-2 with LoRA (Low-Rank Adaptation). This project demonstrates efficient training techniques that achieve 10-15x faster training while maintaining high code generation quality.

## Project Overview

**Problem Statement**: Generate syntactically and semantically valid C++ code from structured pseudo-code instructions.

**Solution**: Fine-tune DistilGPT-2 using the SPoC dataset with LoRA for efficient adaptation and dynamic padding optimizations.

### Key Features
- ‚úÖ **10-15x Faster Training** with dynamic padding and optimization techniques
- ‚úÖ **LoRA Fine-tuning** with only 1.94% trainable parameters
- ‚úÖ **Interactive Gradio Interface** for real-time code generation
- ‚úÖ **Comprehensive Evaluation** with BLEU scores and human assessment
- ‚úÖ **Production-ready** with efficient inference capabilities

## ‚ö° Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/your-username/pseudo-code-to-cpp.git
cd pseudo-code-to-cpp

# Install dependencies
pip install -r requirements.txt

# Additional packages for training
pip install torch transformers datasets peft evaluate gradio
```

### Basic Usage

```python
from code_generation import main_optimized

# Run with recommended settings (15-20 minutes training)
main_optimized(
    model_name="distilgpt2",
    target_samples=5000,
    num_epochs=3,
    skip_training=False,
    skip_app=False
)
```

### Quick Code Generation

```python
from code_generator import CodeGenerator

# Initialize generator
generator = CodeGenerator("final_spoc_model")

# Generate C++ code from pseudo-code
pseudo_code = "for i in range(0, 10): print i"
cpp_code = generator.generate(pseudo_code)
print(cpp_code)
```


## üìä Dataset

### SPoC Dataset
- **Full Name**: Structured Pseudo-code to Code
- **Source**: [SPoC GitHub](https://github.com/sumith1896/spoc)
- **Research Paper**: [SPoC Paper](https://arxiv.org/pdf/1906.04908)

### Dataset Statistics
- **Total Samples**: 280,000+ pseudo-code to C++ pairs
- **Average Pseudo-code Length**: 6.1 words
- **Average Code Length**: 5.5 words
- **Maximum Sequence Length**: 184 tokens

### Data Splits
- **Training**: 28,000 samples
- **Validation**: 3,500 samples
- **Testing**: 3,500 samples

### Sample Data
| Pseudo-code | C++ Code |
|-------------|----------|
| `for i in range(0, 10): print i` | `for(int i=0; i<10; i++) { cout << i << endl; }` |
| `if x > 5: return true else return false` | `bool check(int x) { return x > 5; }` |

## üèóÔ∏è Model Architecture

### Base Model
- **Model**: `distilgpt2` (82M parameters)
- **Architecture**: GPT-2 decoder-only transformer
- **Context Length**: 384 tokens
- **Special Tokens**: Added `<|PSEUDO|>` and `<|CODE|>` for structured generation

### LoRA Configuration
```python
lora_config = LoraConfig(
    r=32,                          # Rank
    lora_alpha=64,                 # LoRA alpha
    target_modules=["c_attn", "c_proj"],  # GPT-2 attention modules
    lora_dropout=0.05,             # Dropout rate
    bias="none",                   # No bias
    task_type=TaskType.CAUSAL_LM   # Causal language modeling
)
```

### Training Optimizations
- **Dynamic Padding**: 92% computation reduction
- **FP16 Mixed Precision**: 2x speedup
- **Gradient Accumulation**: Effective batch size of 32
- **Gradient Checkpointing**: Memory optimization

## ‚ö° Performance

### Training Efficiency
| Metric | Value |
|--------|-------|
| **Training Time** | 47 minutes (15 epochs) |
| **Training Speed** | 4.74 iterations/second |
| **Trainable Parameters** | 1.62M (1.94% of total) |
| **Final Training Loss** | 0.3272 |
| **Final Validation Loss** | 0.2770 |

### Generation Quality
- **BLEU Score**: 0.0335
- **Successful Generations**: 100%
- **Empty Generations**: 0%
- **Average Generation Length**: 171.6 tokens

## üîß Usage

### 1. Data Processing

```python
from src.data_processor import SPoCDataProcessor

processor = SPoCDataProcessor()
dataset_info = processor.preprocess_spoc_smart(target_samples=5000)
data = dataset_info['data']
```

### 2. Model Training

```python
from src.model_trainer import CodeGenTrainer

trainer = CodeGenTrainer()
model, tokenizer = trainer.prepare_model("distilgpt2")
dataset = trainer.build_dataset_optimized(data, tokenizer)
trainer.train_model_optimized(model, tokenizer, dataset)
```

### 3. Code Generation

```python
from src.code_generator import CodeGenerator

generator = CodeGenerator("final_spoc_model")

# Single generation
pseudo_code = "function add(a, b): return a + b"
cpp_code = generator.generate(pseudo_code)

# Batch generation
pseudo_list = [
    "for i in range(0, n): sum += i",
    "if score > 90: grade = 'A'",
    "while x > 0: x = x - 1"
]
results = generator.generate_batch(pseudo_list)
```

### 4. Evaluation

```python
from src.evaluator import ModelEvaluator

evaluator = ModelEvaluator()
metrics = evaluator.evaluate_model(model, tokenizer, data)
print(f"BLEU Score: {metrics['bleu_score']}")
```

## üåê Web Interface

Launch the interactive Gradio app:

```python
python app/gradio_app.py
```

Or from code:

```python
from app.gradio_app import launch_app
launch_app(model, tokenizer)
```

The interface provides:
- Real-time code generation
- Syntax-highlighted C++ output
- Example pseudo-code templates
- Adjustable generation parameters

## üìà Example Generations

### Example 1: Simple Loop
**Input Pseudo-code**:
```
for i in range(0, 10): print i
```

**Generated C++**:
```cpp
#include <iostream>
using namespace std;

int main() {
    for (int i = 0; i < 10; i++) {
        cout << i << endl;
    }
    return 0;
}
```

### Example 2: Conditional Function
**Input Pseudo-code**:
```
if x > 5: return true else return false
```

**Generated C++**:
```cpp
bool checkValue(int x) {
    if (x > 5) {
        return true;
    } else {
        return false;
    }
}
```

### Example 3: Mathematical Function
**Input Pseudo-code**:
```
function add(a, b): return a + b
```

**Generated C++**:
```cpp
int add(int a, int b) {
    return a + b;
}
```

## üöÄ Deployment

### Local API Server

```python
from fastapi import FastAPI
from src.code_generator import CodeGenerator

app = FastAPI()
generator = CodeGenerator("final_spoc_model")

@app.post("/generate")
async def generate_code(pseudo_code: str):
    result = generator.generate(pseudo_code)
    return {"pseudo_code": pseudo_code, "generated_code": result}
```

### Docker Deployment

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ‚öôÔ∏è Configuration

### Training Parameters
```python
# config.py
TRAINING_CONFIG = {
    'model_name': 'distilgpt2',
    'target_samples': 5000,
    'max_length': 384,
    'num_epochs': 3,
    'batch_size': 16,
    'learning_rate': 5e-5,
    'lora_r': 32,
    'lora_alpha': 64
}
```

### Generation Parameters
```python
GENERATION_CONFIG = {
    'max_new_tokens': 256,
    'temperature': 0.3,
    'top_p': 0.9,
    'repetition_penalty': 1.1,
    'do_sample': True
}
```

## üéØ Use Cases

### Educational Applications
- **Programming Tutoring**: Help students understand pseudo-code translation
- **Algorithm Learning**: Demonstrate multiple implementations
- **Code Comprehension**: Bridge between logic and implementation

### Development Tools
- **Rapid Prototyping**: Generate boilerplate code quickly
- **Code Documentation**: Convert pseudo-code to executable examples
- **Interview Preparation**: Practice pseudo-code to code conversion

### Research Applications
- **Code Generation Research**: Baseline for new models
- **Educational Technology**: Automated programming assistance
- **AI Programming**: Study of semantic understanding

## ü§ù Contributing

We welcome contributions! 

### Development Setup
```bash
# Fork and clone
git clone https://github.com/your-username/pseudo-code-to-cpp.git
cd pseudo-code-to-cpp

# Create environment
conda create -n codegen python=3.9
conda activate codegen

# Install development dependencies
pip install -r requirements-dev.txt
```

### Areas for Contribution
- Support for more programming languages
- Enhanced evaluation metrics
- Better prompt engineering
- Web interface improvements
- Performance optimizations

## üìÑ License

This project is licensed under the MIT License 

## üôè Acknowledgments

- **Hugging Face** for transformers and PEFT libraries
- **SPoC Dataset** authors for the high-quality dataset
- **Google Colab** for computational resources
- **LoRA** authors for efficient fine-tuning technique
- **GPT-2** team for the foundational model

---


**‚≠ê If you find this project useful, please give it a star on GitHub!**
